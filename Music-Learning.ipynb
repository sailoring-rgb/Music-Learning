{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from collections import Counter\n",
    "import random\n",
    "import IPython\n",
    "from IPython.display import Image, Audio\n",
    "import music21\n",
    "from music21 import *\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(\"ignore\")\n",
    "np.random.seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To accomplish this project, we are using MIDI files of classical piano music, to be more precise: <ins>**Beethoven's compositions**</ins>.\n",
    "\n",
    "- Initially, we will generate a list comprising every song in the **Beethoven** folder,parsed as a *music21* stream.\n",
    "\n",
    "- Later, we will create a function to extract both chords and notes from the data, transforming it into a **corpus**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and parsing the midi files as stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../input/beeth/\"\n",
    "\n",
    "all_midis= []\n",
    "for i in os.listdir(filepath):\n",
    "    if i.endswith(\".mid\"):\n",
    "        tr = filepath+i\n",
    "        midi = converter.parse(tr)\n",
    "        all_midis.append(midi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will extract the elements from these MIDI file streams. The dataset specifies that the MIDI files exclusively contain piano recordings. Hence, the extracted components will consist of either piano chords or individual piano notes.\n",
    "\n",
    "<ins>Difference between notes and chords:</ins>\n",
    "\n",
    "- **[NOTE]** The musical notes serve as the building blocks of music, representing pitches associated to distinct audio vibrations. Notably, Western music employs a set of 12 musical notes.\n",
    "\n",
    "- **[Chord]** A collection of harmonious notes.\n",
    "\n",
    "The previously created music21 stream in the preceding cell contains a mixture of chords and notes. Our **goal** is to extract them specifically as individual notes, resulting in <ins>a series of notes forming the musical composition</ins>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the list of notes as corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_notes(file):\n",
    "    notes = []\n",
    "    pick = None\n",
    "    for j in file:\n",
    "        songs = instrument.partitionByInstrument(j)\n",
    "        for part in songs.parts:\n",
    "            pick = part.recurse()\n",
    "            for element in pick:\n",
    "                if isinstance(element, note.Note):\n",
    "                    notes.append(str(element.pitch))\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    notes.append(\".\".join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    return notes\n",
    "\n",
    "Corpus= extract_notes(all_midis)\n",
    "print(\"Total notes in evey Beethoven midi in the dataset: \", len(Corpus))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing the first 50 values in corpus"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these values correspond to the notes, as previously mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First fifty values in the Corpus:\", Corpus[:50])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing the music sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(music):\n",
    "    display(Image(str(music.write(\"lily.png\"))))\n",
    "    \n",
    "def chords_n_notes(Snippet):\n",
    "    Melody = []\n",
    "    offset = 0\n",
    "    for i in Snippet:\n",
    "        # In case it is a chord\n",
    "        if (\".\" in i or i.isdigit()):\n",
    "            chord_notes = i.split(\".\")\n",
    "            notes = [] \n",
    "            for j in chord_notes:\n",
    "                inst_note=int(j)\n",
    "                note_snip = note.Note(inst_note)            \n",
    "                notes.append(note_snip)\n",
    "                chord_snip = chord.Chord(notes)\n",
    "                chord_snip.offset = offset\n",
    "                Melody.append(chord_snip)\n",
    "        # In case it is a note\n",
    "        else: \n",
    "            note_snip = note.Note(i)\n",
    "            note_snip.offset = offset\n",
    "            Melody.append(note_snip)\n",
    "\n",
    "        offset += 1\n",
    "        \n",
    "    Melody_midi = stream.Stream(Melody)   \n",
    "    return Melody_midi\n",
    "\n",
    "Melody_Snippet = chords_n_notes(Corpus[:100])\n",
    "show(Melody_Snippet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing the above sheet music"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have generated a \".wav\" file with the same content outside of this code. We are using it to establish an audio interface. Now, let's take a moment to listen to the data corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sample Audio From Data\")\n",
    "IPython.display.Audio(\"../input/music-generated-lstm/Corpus_Snippet.wav\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining every note in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_num = Counter(Corpus)\n",
    "print(\"Total of unique notes in the corpus: \", len(count_num))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the prev notes dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Notes = list(count_num.keys())\n",
    "Recurrence = list(count_num.values())\n",
    "\n",
    "# Average recurrency for a note in corpus\n",
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "print(\"Average recurrency for a note in corpus: \", Average(Recurrence))\n",
    "print(\"Most frequent note in corpus appeared: \", max(Recurrence), \" times\")\n",
    "print(\"Least frequent note in corpus appeared: \", min(Recurrence), \" time\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the distribution of notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,3),facecolor=\"#97BACB\")\n",
    "bins = np.arange(0,(max(Recurrence)), 50) \n",
    "plt.hist(Recurrence, bins=bins, color=\"#97BACB\")\n",
    "plt.axvline(x=100,color=\"#DBACC1\")\n",
    "plt.title(\"Frequency distribution of notes in the corpus\")\n",
    "plt.xlabel(\"Frequency of chords in corpus\")\n",
    "plt.ylabel(\"Number of chords\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **existence of rare notes** in the corpus can potentially lead to numerous issues, encountered while composing this piece. To prevent encountering error reports, let's examine the frequency of the notes. For the sake of simplicity, we will exclude some of the least occurring notes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Getting** a list of rare chords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_note = []\n",
    "for index, (key, value) in enumerate(count_num.items()):\n",
    "    if value < 100:\n",
    "        m =  key\n",
    "        rare_note.append(m)\n",
    "        \n",
    "print(\"Total number of notes that occur less than 100 times: \", len(rare_note))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Eliminating** the rare notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in Corpus:\n",
    "    if element in rare_note:\n",
    "        Corpus.remove(element)\n",
    "\n",
    "print(\"Length of corpus after elemination the rare notes: \", len(Corpus))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes can be understood as sound waves. In music, we have specific combinations of frequency and wavelength that are standardized as notes. In our corpus, we have the names of these notes. When we loaded the data using the *music21* library, it provided us with the **frequency**, **wavelength**, **duration**, and other information for each note."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing all the unique characters present in my corpus to bult a dictionary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a dictionary to establish a mapping between the notes and their corresponding indices. Since computers perceive these note names as symbols, we need this dictionary to associate each unique note in our corpus with a specific number. This mapping will be used to encode and decode information when interacting with the RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symb = sorted(list(set(Corpus)))\n",
    "\n",
    "L_corpus = len(Corpus)\n",
    "L_symb = len(symb)\n",
    "\n",
    "mapping = dict((c, i) for i, c in enumerate(symb))\n",
    "reverse_mapping = dict((i, c) for i, c in enumerate(symb))\n",
    "\n",
    "print(\"Total number of characters: \", L_corpus)\n",
    "print(\"Number of unique characters: \", L_symb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding and splitting the corpus as labels and targets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will encode the corpus by converting it into smaller sequences of equal length. Each sequence will consist of both the features and the corresponding targets. The features and targets will be represented by the mapped indices from the dictionary, indicating unique characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 40\n",
    "features = []\n",
    "targets = []\n",
    "for i in range(0, L_corpus - length, 1):\n",
    "    feature = Corpus[i:i + length]\n",
    "    target = Corpus[i + length]\n",
    "    features.append([mapping[j] for j in feature])\n",
    "    targets.append(mapping[target])\n",
    "    \n",
    "    \n",
    "L_datapoints = len(targets)\n",
    "print(\"Total number of sequences in the corpus: \", L_datapoints)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <ins>labels</ins> will be **reshaped** and **normalized**, while the <ins>targets</ins> themselves will be **one-hot encoded**. These processed inputs will be fed into the RNN for training. However, before that, we need to build the RNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X and normalize\n",
    "X = (np.reshape(features, (L_datapoints, length, 1)))/ float(L_symb)\n",
    "# one hot encode the output variable\n",
    "y = tensorflow.keras.utils.to_categorical(targets) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate music, we will need to provide some input to the RNN. For this purpose, we will set aside a portion of the data as \"seeds.\" Although we could have trained the model using the entire dataset, as non-musicians, we are not capable of coming up with a suitable input seed value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_seed, y_train, y_seed = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising and compiling the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(512, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dense(256))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "opt = Adamax(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=256, epochs=200)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having completed the training of our model using the MIDI files of piano music, it's time to evaluate its performance and observe the results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the learning curve for the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "fig = plt.figure(figsize=(15,4), facecolor=\"#97BACB\")\n",
    "fig.suptitle(\"Learning plot of model for loss\")\n",
    "pl=sns.lineplot(data=history_df[\"loss\"],color=\"#444160\")\n",
    "pl.set(ylabel =\"Training Loss\")\n",
    "pl.set(xlabel =\"Epochs\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the melody"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to have music in form or a list of chords and notes so that we can convert it into a midi file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Malody_Generator(Note_Count):\n",
    "    seed = X_seed[np.random.randint(0,len(X_seed)-1)]\n",
    "    Music = \"\"\n",
    "    Notes_Generated=[]\n",
    "    for i in range(Note_Count):\n",
    "        seed = seed.reshape(1,length,1)\n",
    "        prediction = model.predict(seed, verbose=0)[0]\n",
    "        prediction = np.log(prediction) / 1.0\n",
    "        exp_preds = np.exp(prediction)\n",
    "        prediction = exp_preds / np.sum(exp_preds)\n",
    "        index = np.argmax(prediction)\n",
    "        index_N = index/ float(L_symb)   \n",
    "        Notes_Generated.append(index)\n",
    "        Music = [reverse_mapping[char] for char in Notes_Generated]\n",
    "        seed = np.insert(seed[0],len(seed[0]),index_N)\n",
    "        seed = seed[1:]\n",
    "    \n",
    "    Melody = chords_n_notes(Music)\n",
    "    Melody_midi = stream.Stream(Melody)   \n",
    "    return Music,Melody_midi\n",
    "\n",
    "# notes and melody created by the model\n",
    "Music_notes, Melody = Malody_Generator(100)\n",
    "show(Melody)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This certainly resembles music! However, in order to determine if it truly sounds like music, we need to listen to the MIDI file. Unfortunately, playing MIDI files can be cumbersome. To overcome this limitation, we have saved and converted a few generated melodies to the \".wav\" format outside of this notebook. So, let's take a moment to listen and evaluate the melodies."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melody generated: Sample 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Melody.write('midi','Melody_Generated.mid')\n",
    "IPython.display.Audio(\"../input/music-generated-lstm/Melody_Generated 2.wav\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melody generated: Sample 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(\"../input/music-generated-lstm/Melody_Generated_1.wav\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
